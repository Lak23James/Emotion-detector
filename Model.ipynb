{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ce4ebd",
   "metadata": {},
   "source": [
    "Importing The Libraries Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d83d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0e633",
   "metadata": {},
   "source": [
    "#**Data pre processing step and processing step**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fae8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "Batch shape: torch.Size([64, 1, 48, 48])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001E50BECC7F0>\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Constants\n",
    "TRAIN_DIR = 'archive (3) - Copy/train'  \n",
    "TEST_DIR = 'archive (3) - Copy/test'  \n",
    "IMG_SIZE = 48               \n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 2. Define Transforms (The \"Preprocessing\" Step)\n",
    "# This replaces your manual normalization and reshaping\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), # Forces 1 channel (Grayscale)\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),     # Resizes to 48x48\n",
    "    transforms.ToTensor(),                       # Converts to Tensor & Scales to [0, 1]\n",
    "])\n",
    "\n",
    "# 3. Load the Images from Folders\n",
    "train_data = datasets.ImageFolder(root=TRAIN_DIR, transform=data_transforms)\n",
    "test_data = datasets.ImageFolder(root=TEST_DIR, transform=data_transforms)\n",
    "\n",
    "# 4. Create DataLoaders (The \"Feeder\")\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- SANITY CHECK (Run this once to verify) ---\n",
    "print(f\"Classes found: {train_data.classes}\")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\") \n",
    "print(train_loader)\n",
    "# Should print: torch.Size([64, 1, 48, 48]) -> (Batch, Channel, Height, Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcb2d7",
   "metadata": {},
   "source": [
    "**Building The CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fc7682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        # Conv Block 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        # Conv Block 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        # Conv Block 3\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 6 * 6, 128) \n",
    "        self.fc2 = nn.Linear(128, 7) # 7 Classes\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 6 * 6) # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb5b3d",
   "metadata": {},
   "source": [
    "**Applying CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n",
      "Starting Training...\n",
      "Epoch [1/50] -> Loss: 1.7219 | Accuracy: 30.18%\n",
      "Epoch [2/50] -> Loss: 1.5318 | Accuracy: 40.79%\n",
      "Epoch [3/50] -> Loss: 1.4349 | Accuracy: 44.92%\n",
      "Epoch [4/50] -> Loss: 1.3531 | Accuracy: 48.33%\n",
      "Epoch [5/50] -> Loss: 1.2865 | Accuracy: 50.96%\n",
      "Epoch [6/50] -> Loss: 1.2387 | Accuracy: 53.10%\n",
      "Epoch [7/50] -> Loss: 1.1931 | Accuracy: 54.51%\n",
      "Epoch [8/50] -> Loss: 1.1469 | Accuracy: 56.48%\n",
      "Epoch [9/50] -> Loss: 1.1048 | Accuracy: 58.18%\n",
      "Epoch [10/50] -> Loss: 1.0653 | Accuracy: 59.39%\n",
      "Epoch [11/50] -> Loss: 1.0341 | Accuracy: 60.62%\n",
      "Epoch [12/50] -> Loss: 1.0052 | Accuracy: 61.51%\n",
      "Epoch [13/50] -> Loss: 0.9649 | Accuracy: 63.04%\n",
      "Epoch [14/50] -> Loss: 0.9381 | Accuracy: 63.97%\n",
      "Epoch [15/50] -> Loss: 0.8984 | Accuracy: 65.55%\n",
      "Epoch [16/50] -> Loss: 0.8745 | Accuracy: 65.82%\n",
      "Epoch [17/50] -> Loss: 0.8466 | Accuracy: 67.10%\n",
      "Epoch [18/50] -> Loss: 0.8141 | Accuracy: 68.11%\n",
      "Epoch [19/50] -> Loss: 0.7901 | Accuracy: 69.19%\n",
      "Epoch [20/50] -> Loss: 0.7626 | Accuracy: 70.03%\n",
      "Epoch [21/50] -> Loss: 0.7453 | Accuracy: 70.21%\n",
      "Epoch [22/50] -> Loss: 0.7237 | Accuracy: 71.46%\n",
      "Epoch [23/50] -> Loss: 0.6990 | Accuracy: 72.37%\n",
      "Epoch [24/50] -> Loss: 0.6785 | Accuracy: 72.85%\n",
      "Epoch [25/50] -> Loss: 0.6640 | Accuracy: 73.28%\n",
      "Epoch [26/50] -> Loss: 0.6489 | Accuracy: 73.77%\n",
      "Epoch [27/50] -> Loss: 0.6344 | Accuracy: 74.15%\n",
      "Epoch [28/50] -> Loss: 0.6202 | Accuracy: 74.60%\n",
      "Epoch [29/50] -> Loss: 0.6027 | Accuracy: 75.53%\n",
      "Epoch [30/50] -> Loss: 0.5972 | Accuracy: 75.62%\n",
      "Epoch [31/50] -> Loss: 0.5741 | Accuracy: 76.24%\n",
      "Epoch [32/50] -> Loss: 0.5732 | Accuracy: 76.46%\n",
      "Epoch [33/50] -> Loss: 0.5526 | Accuracy: 77.17%\n",
      "Epoch [34/50] -> Loss: 0.5505 | Accuracy: 77.27%\n",
      "Epoch [35/50] -> Loss: 0.5414 | Accuracy: 77.49%\n",
      "Epoch [36/50] -> Loss: 0.5209 | Accuracy: 78.68%\n",
      "Epoch [37/50] -> Loss: 0.5241 | Accuracy: 78.14%\n",
      "Epoch [38/50] -> Loss: 0.5069 | Accuracy: 78.79%\n",
      "Epoch [39/50] -> Loss: 0.5064 | Accuracy: 78.80%\n",
      "Epoch [40/50] -> Loss: 0.4963 | Accuracy: 79.35%\n",
      "Epoch [41/50] -> Loss: 0.4882 | Accuracy: 79.66%\n",
      "Epoch [42/50] -> Loss: 0.4805 | Accuracy: 80.03%\n",
      "Epoch [43/50] -> Loss: 0.4830 | Accuracy: 80.14%\n",
      "Epoch [44/50] -> Loss: 0.4707 | Accuracy: 80.21%\n",
      "Epoch [45/50] -> Loss: 0.4723 | Accuracy: 80.18%\n",
      "Epoch [46/50] -> Loss: 0.4656 | Accuracy: 80.69%\n",
      "Epoch [47/50] -> Loss: 0.4602 | Accuracy: 80.64%\n",
      "Epoch [48/50] -> Loss: 0.4454 | Accuracy: 81.38%\n",
      "Epoch [49/50] -> Loss: 0.4462 | Accuracy: 81.15%\n",
      "Epoch [50/50] -> Loss: 0.4404 | Accuracy: 81.34%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. Setup Device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# 2. Instantiate Model, Loss, and Optimizer\n",
    "model = EmotionCNN().to(device) # Move model to GPU/CPU\n",
    "criterion = nn.CrossEntropyLoss() # Handles Softmax automatically\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # standard learning rate\n",
    "\n",
    "# 3. The Training Function\n",
    "def train_model(num_epochs):\n",
    "    print(\"Starting Training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # A. Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # B. Backward Pass & Optimization\n",
    "            optimizer.zero_grad() # Clear old gradients\n",
    "            loss.backward()       # Calculate new gradients\n",
    "            optimizer.step()      # Update weights\n",
    "            \n",
    "            # C. Track Stats\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        # Print stats after every epoch\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] -> Loss: {running_loss/len(train_loader):.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "train_model(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST DATA RESULTS ---\n",
      "Checking accuracy...\n",
      "Got 4005 / 7178 correct (55.80%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.79548620785734"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    print(\"Checking accuracy...\") # Simple print to start\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "           \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            # Count correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "    # Calculate math\n",
    "    acc = float(num_correct) / float(num_samples) * 100\n",
    "    print(f'Got {num_correct} / {num_samples} correct ({acc:.2f}%)')\n",
    "    \n",
    "    model.train() \n",
    "    return acc\n",
    "\n",
    "-\n",
    "print(\"--- TEST DATA RESULTS ---\")\n",
    "check_accuracy(test_loader, model)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81a2b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REAL-TIME EMOTION CHECK ---\n",
      "Testing Model on 10 Random Images...\n",
      "\n",
      "Img 1: True: Neutral    | Pred: Sad        (42.5%) -> WRONG  \n",
      "Img 2: True: Happy      | Pred: Happy      (100.0%) -> CORRECT\n",
      "Img 3: True: Sad        | Pred: Neutral    (72.4%) -> WRONG  \n",
      "Img 4: True: Happy      | Pred: Fear       (86.7%) -> WRONG  \n",
      "Img 5: True: Angry      | Pred: Angry      (87.1%) -> CORRECT\n",
      "Img 6: True: Neutral    | Pred: Fear       (69.0%) -> WRONG  \n",
      "Img 7: True: Surprise   | Pred: Fear       (50.4%) -> WRONG  \n",
      "Img 8: True: Happy      | Pred: Sad        (76.7%) -> WRONG  \n",
      "Img 9: True: Sad        | Pred: Neutral    (88.5%) -> WRONG  \n",
      "Img 10: True: Happy      | Pred: Happy      (100.0%) -> CORRECT\n",
      "--------------------------------------------------\n",
      "Mini-Batch Accuracy: 3/10\n"
     ]
    }
   ],
  

 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
