{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ce4ebd",
   "metadata": {},
   "source": [
    "Importing The Libraries Required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d83d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "import torch\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb0e633",
   "metadata": {},
   "source": [
    "#**Data pre processing step and processing step**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fae8c87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
      "Batch shape: torch.Size([64, 1, 48, 48])\n",
      "<torch.utils.data.dataloader.DataLoader object at 0x000001E50BECC7F0>\n"
     ]
    }
   ],
   "source": [
    "# 1. Define Constants\n",
    "TRAIN_DIR = 'archive (3) - Copy/train'  \n",
    "TEST_DIR = 'archive (3) - Copy/test'  \n",
    "IMG_SIZE = 48               \n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 2. Define Transforms (The \"Preprocessing\" Step)\n",
    "# This replaces your manual normalization and reshaping\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1), # Forces 1 channel (Grayscale)\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),     # Resizes to 48x48\n",
    "    transforms.ToTensor(),                       # Converts to Tensor & Scales to [0, 1]\n",
    "])\n",
    "\n",
    "# 3. Load the Images from Folders\n",
    "train_data = datasets.ImageFolder(root=TRAIN_DIR, transform=data_transforms)\n",
    "test_data = datasets.ImageFolder(root=TEST_DIR, transform=data_transforms)\n",
    "\n",
    "# 4. Create DataLoaders (The \"Feeder\")\n",
    "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# --- SANITY CHECK (Run this once to verify) ---\n",
    "print(f\"Classes found: {train_data.classes}\")\n",
    "images, labels = next(iter(train_loader))\n",
    "print(f\"Batch shape: {images.shape}\") \n",
    "print(train_loader)\n",
    "# Should print: torch.Size([64, 1, 48, 48]) -> (Batch, Channel, Height, Width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1dcb2d7",
   "metadata": {},
   "source": [
    "**Building The CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fc7682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(EmotionCNN, self).__init__()\n",
    "        # Conv Block 1\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        # Conv Block 2\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        # Conv Block 3\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(128 * 6 * 6, 128) \n",
    "        self.fc2 = nn.Linear(128, 7) # 7 Classes\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128 * 6 * 6) # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb5b3d",
   "metadata": {},
   "source": [
    "**Applying CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bb40e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on: cpu\n",
      "Starting Training...\n",
      "Epoch [1/50] -> Loss: 1.7219 | Accuracy: 30.18%\n",
      "Epoch [2/50] -> Loss: 1.5318 | Accuracy: 40.79%\n",
      "Epoch [3/50] -> Loss: 1.4349 | Accuracy: 44.92%\n",
      "Epoch [4/50] -> Loss: 1.3531 | Accuracy: 48.33%\n",
      "Epoch [5/50] -> Loss: 1.2865 | Accuracy: 50.96%\n",
      "Epoch [6/50] -> Loss: 1.2387 | Accuracy: 53.10%\n",
      "Epoch [7/50] -> Loss: 1.1931 | Accuracy: 54.51%\n",
      "Epoch [8/50] -> Loss: 1.1469 | Accuracy: 56.48%\n",
      "Epoch [9/50] -> Loss: 1.1048 | Accuracy: 58.18%\n",
      "Epoch [10/50] -> Loss: 1.0653 | Accuracy: 59.39%\n",
      "Epoch [11/50] -> Loss: 1.0341 | Accuracy: 60.62%\n",
      "Epoch [12/50] -> Loss: 1.0052 | Accuracy: 61.51%\n",
      "Epoch [13/50] -> Loss: 0.9649 | Accuracy: 63.04%\n",
      "Epoch [14/50] -> Loss: 0.9381 | Accuracy: 63.97%\n",
      "Epoch [15/50] -> Loss: 0.8984 | Accuracy: 65.55%\n",
      "Epoch [16/50] -> Loss: 0.8745 | Accuracy: 65.82%\n",
      "Epoch [17/50] -> Loss: 0.8466 | Accuracy: 67.10%\n",
      "Epoch [18/50] -> Loss: 0.8141 | Accuracy: 68.11%\n",
      "Epoch [19/50] -> Loss: 0.7901 | Accuracy: 69.19%\n",
      "Epoch [20/50] -> Loss: 0.7626 | Accuracy: 70.03%\n",
      "Epoch [21/50] -> Loss: 0.7453 | Accuracy: 70.21%\n",
      "Epoch [22/50] -> Loss: 0.7237 | Accuracy: 71.46%\n",
      "Epoch [23/50] -> Loss: 0.6990 | Accuracy: 72.37%\n",
      "Epoch [24/50] -> Loss: 0.6785 | Accuracy: 72.85%\n",
      "Epoch [25/50] -> Loss: 0.6640 | Accuracy: 73.28%\n",
      "Epoch [26/50] -> Loss: 0.6489 | Accuracy: 73.77%\n",
      "Epoch [27/50] -> Loss: 0.6344 | Accuracy: 74.15%\n",
      "Epoch [28/50] -> Loss: 0.6202 | Accuracy: 74.60%\n",
      "Epoch [29/50] -> Loss: 0.6027 | Accuracy: 75.53%\n",
      "Epoch [30/50] -> Loss: 0.5972 | Accuracy: 75.62%\n",
      "Epoch [31/50] -> Loss: 0.5741 | Accuracy: 76.24%\n",
      "Epoch [32/50] -> Loss: 0.5732 | Accuracy: 76.46%\n",
      "Epoch [33/50] -> Loss: 0.5526 | Accuracy: 77.17%\n",
      "Epoch [34/50] -> Loss: 0.5505 | Accuracy: 77.27%\n",
      "Epoch [35/50] -> Loss: 0.5414 | Accuracy: 77.49%\n",
      "Epoch [36/50] -> Loss: 0.5209 | Accuracy: 78.68%\n",
      "Epoch [37/50] -> Loss: 0.5241 | Accuracy: 78.14%\n",
      "Epoch [38/50] -> Loss: 0.5069 | Accuracy: 78.79%\n",
      "Epoch [39/50] -> Loss: 0.5064 | Accuracy: 78.80%\n",
      "Epoch [40/50] -> Loss: 0.4963 | Accuracy: 79.35%\n",
      "Epoch [41/50] -> Loss: 0.4882 | Accuracy: 79.66%\n",
      "Epoch [42/50] -> Loss: 0.4805 | Accuracy: 80.03%\n",
      "Epoch [43/50] -> Loss: 0.4830 | Accuracy: 80.14%\n",
      "Epoch [44/50] -> Loss: 0.4707 | Accuracy: 80.21%\n",
      "Epoch [45/50] -> Loss: 0.4723 | Accuracy: 80.18%\n",
      "Epoch [46/50] -> Loss: 0.4656 | Accuracy: 80.69%\n",
      "Epoch [47/50] -> Loss: 0.4602 | Accuracy: 80.64%\n",
      "Epoch [48/50] -> Loss: 0.4454 | Accuracy: 81.38%\n",
      "Epoch [49/50] -> Loss: 0.4462 | Accuracy: 81.15%\n",
      "Epoch [50/50] -> Loss: 0.4404 | Accuracy: 81.34%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 1. Setup Device \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Training on: {device}\")\n",
    "\n",
    "# 2. Instantiate Model, Loss, and Optimizer\n",
    "model = EmotionCNN().to(device) # Move model to GPU/CPU\n",
    "criterion = nn.CrossEntropyLoss() # Handles Softmax automatically\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # standard learning rate\n",
    "\n",
    "# 3. The Training Function\n",
    "def train_model(num_epochs):\n",
    "    print(\"Starting Training...\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Set to training mode\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            \n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            # A. Forward Pass\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # B. Backward Pass & Optimization\n",
    "            optimizer.zero_grad() # Clear old gradients\n",
    "            loss.backward()       # Calculate new gradients\n",
    "            optimizer.step()      # Update weights\n",
    "            \n",
    "            # C. Track Stats\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        # Print stats after every epoch\n",
    "        epoch_acc = 100 * correct / total\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] -> Loss: {running_loss/len(train_loader):.4f} | Accuracy: {epoch_acc:.2f}%\")\n",
    "\n",
    "train_model(num_epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3cd014c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TEST DATA RESULTS ---\n",
      "Checking accuracy...\n",
      "Got 4005 / 7178 correct (55.80%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55.79548620785734"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    print(\"Checking accuracy...\") # Simple print to start\n",
    "    \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "           \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            \n",
    "            # Count correct\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        \n",
    "    # Calculate math\n",
    "    acc = float(num_correct) / float(num_samples) * 100\n",
    "    print(f'Got {num_correct} / {num_samples} correct ({acc:.2f}%)')\n",
    "    \n",
    "    model.train() \n",
    "    return acc\n",
    "\n",
    "\n",
    "print(\"--- TEST DATA RESULTS ---\")\n",
    "check_accuracy(test_loader, model)\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe910247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes detected: ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
      "Checking Training Data...\n",
      "\n",
      "==================== Evaluating TRAINING Set ====================\n",
      "Overall Accuracy: 93.99%\n",
      "\n",
      "--- Detailed Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.92      0.91      0.92      3995\n",
      "     Disgust       0.99      0.92      0.95       436\n",
      "        Fear       0.93      0.88      0.90      4097\n",
      "       Happy       0.98      0.98      0.98      7215\n",
      "     Neutral       0.93      0.95      0.94      4965\n",
      "         Sad       0.89      0.94      0.91      4830\n",
      "    Surprise       0.97      0.96      0.97      3171\n",
      "\n",
      "    accuracy                           0.94     28709\n",
      "   macro avg       0.94      0.93      0.94     28709\n",
      "weighted avg       0.94      0.94      0.94     28709\n",
      "\n",
      "\n",
      "--- Confusion Matrix (Row=True, Col=Pred) ---\n",
      "               Pred Angry  Pred Disgust  Pred Fear  Pred Happy  Pred Neutral  \\\n",
      "True Angry           3630             3        110          11            70   \n",
      "True Disgust           24           399          3           0             2   \n",
      "True Fear             104             3       3601          13            77   \n",
      "True Happy             22             0         13        7090            53   \n",
      "True Neutral           53             0         33          51          4693   \n",
      "True Sad               81             0         86          15           128   \n",
      "True Surprise          16             0         45          31            15   \n",
      "\n",
      "               Pred Sad  Pred Surprise  \n",
      "True Angry          168              3  \n",
      "True Disgust          8              0  \n",
      "True Fear           225             74  \n",
      "True Happy           21             16  \n",
      "True Neutral        132              3  \n",
      "True Sad           4518              2  \n",
      "True Surprise        11           3053  \n",
      "Checking Testing Data...\n",
      "\n",
      "==================== Evaluating TESTING Set ====================\n",
      "Overall Accuracy: 55.80%\n",
      "\n",
      "--- Detailed Classification Report ---\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Angry       0.44      0.51      0.47       958\n",
      "     Disgust       0.81      0.38      0.52       111\n",
      "        Fear       0.40      0.40      0.40      1024\n",
      "       Happy       0.76      0.75      0.76      1774\n",
      "     Neutral       0.50      0.52      0.51      1233\n",
      "         Sad       0.42      0.40      0.41      1247\n",
      "    Surprise       0.75      0.71      0.73       831\n",
      "\n",
      "    accuracy                           0.56      7178\n",
      "   macro avg       0.58      0.52      0.54      7178\n",
      "weighted avg       0.56      0.56      0.56      7178\n",
      "\n",
      "\n",
      "--- Confusion Matrix (Row=True, Col=Pred) ---\n",
      "               Pred Angry  Pred Disgust  Pred Fear  Pred Happy  Pred Neutral  \\\n",
      "True Angry            491             4        128          72            95   \n",
      "True Disgust           27            42         15           4             9   \n",
      "True Fear             133             1        407          65           124   \n",
      "True Happy             96             1         76        1338           140   \n",
      "True Neutral          141             2        111         115           644   \n",
      "True Sad              179             2        185         112           249   \n",
      "True Surprise          43             0         98          48            32   \n",
      "\n",
      "               Pred Sad  Pred Surprise  \n",
      "True Angry          140             28  \n",
      "True Disgust         14              0  \n",
      "True Fear           206             88  \n",
      "True Happy           90             33  \n",
      "True Neutral        200             20  \n",
      "True Sad            496             24  \n",
      "True Surprise        23            587  \n",
      "\n",
      "==================================================\n",
      "FINAL DIAGNOSIS:\n",
      ">> Metrics look balanced (or both are equally average).\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_dataset(model, loader, dataset_name, classes):\n",
    "    \"\"\"\n",
    "    Runs the model on a dataset and prints detailed metrics.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    print(f\"\\n{'='*20} Evaluating {dataset_name} Set {'='*20}\")\n",
    "    \n",
    "    # Disable gradient calculation for speed\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            # Move data to the same device as model\n",
    "            images = images.to(device) \n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            # Store results (move to CPU and convert to numpy)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "            y_pred.extend(predicted.cpu().numpy())\n",
    "\n",
    "    # --- 1. Overall Accuracy ---\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Overall Accuracy: {acc*100:.2f}%\")\n",
    "    \n",
    "    # --- 2. Detailed Metrics (Precision, Recall, F1) ---\n",
    "    print(\"\\n--- Detailed Classification Report ---\")\n",
    "    print(classification_report(y_true, y_pred, target_names=classes, zero_division=0))\n",
    "    \n",
    "    # --- 3. Confusion Matrix (Where is the model getting confused?) ---\n",
    "    # Convert to DataFrame for better readability\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    cm_df = pd.DataFrame(cm, index=[f\"True {c}\" for c in classes], \n",
    "                         columns=[f\"Pred {c}\" for c in classes])\n",
    "    \n",
    "    print(\"\\n--- Confusion Matrix (Row=True, Col=Pred) ---\")\n",
    "    print(cm_df)\n",
    "    \n",
    "    return acc\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Ensure 'device' is defined\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Ensure 'classes' matches your training folder structure exactly\n",
    "# Example: classes = ['Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise']\n",
    "# If you used ImageFolder, you can get this via: train_dataset.classes\n",
    "print(f\"Classes detected: {classes}\")\n",
    "\n",
    "# --- RUN EVALUATION ---\n",
    "\n",
    "# 1. Check Training Data (To see if it learned at all)\n",
    "print(\"Checking Training Data...\")\n",
    "train_acc = evaluate_dataset(model, train_loader, \"TRAINING\", classes)\n",
    "\n",
    "# 2. Check Testing Data (To see if it generalizes)\n",
    "print(\"Checking Testing Data...\")\n",
    "test_acc = evaluate_dataset(model, test_loader, \"TESTING\", classes)\n",
    "\n",
    "# --- DIAGNOSIS ---\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"FINAL DIAGNOSIS:\")\n",
    "if train_acc > 0.90 and test_acc < 0.50:\n",
    "    print(\">> OVERFITTING DETECTED.\")\n",
    "    print(\"The model memorized the training images but fails on new ones.\")\n",
    "    print(\"Try: Dropout layers, Data Augmentation, or fewer epochs.\")\n",
    "elif train_acc < 0.50:\n",
    "    print(\">> UNDERFITTING DETECTED.\")\n",
    "    print(\"The model isn't learning well enough yet.\")\n",
    "    print(\"Try: More epochs, a more complex model (ResNet), or checking learning rate.\")\n",
    "else:\n",
    "    print(\">> Metrics look balanced (or both are equally average).\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2b215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- REAL-TIME EMOTION CHECK ---\n",
      "Testing Model on 10 Random Images...\n",
      "\n",
      "Img 1: True: Neutral    | Pred: Sad        (42.5%) -> WRONG  \n",
      "Img 2: True: Happy      | Pred: Happy      (100.0%) -> CORRECT\n",
      "Img 3: True: Sad        | Pred: Neutral    (72.4%) -> WRONG  \n",
      "Img 4: True: Happy      | Pred: Fear       (86.7%) -> WRONG  \n",
      "Img 5: True: Angry      | Pred: Angry      (87.1%) -> CORRECT\n",
      "Img 6: True: Neutral    | Pred: Fear       (69.0%) -> WRONG  \n",
      "Img 7: True: Surprise   | Pred: Fear       (50.4%) -> WRONG  \n",
      "Img 8: True: Happy      | Pred: Sad        (76.7%) -> WRONG  \n",
      "Img 9: True: Sad        | Pred: Neutral    (88.5%) -> WRONG  \n",
      "Img 10: True: Happy      | Pred: Happy      (100.0%) -> CORRECT\n",
      "--------------------------------------------------\n",
      "Mini-Batch Accuracy: 3/10\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
